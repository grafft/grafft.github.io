---
---
@string{aps = {American Physical Society,}}

@inproceedings{Zholus2023,
  bibtex_show={true},
  preview={brownian-motion.gif},
  abbr={NeuroInfo},
  html={https://link.springer.com/10.1007/978-3-031-19032-2_3},
  pdf={example_pdf.pdf},
  dimensions={true},
  selected={true},
  title = {Addressing {Task} {Prioritization} in {Model}-based {Reinforcement} {Learning}},
  booktitle = {Advances in Neural Computation, Machine Learning, and Cognitive Research VI. NEUROINFORMATICS 2022. Studies in Computational Intelligence},
  author = {Zholus, Artem and Ivchenkov, Yaroslav and Panov, Aleksandr I},
  editor = {Kryzhanovsky, B. and Dunin-Barkowski, W. and Redko, V. and Tiumentsev, Y.},
  year = {2023},
  pages = {19--30},
  volume = {1064},
  isbn = {978-3-031-19031-5},
  url = {https://link.springer.com/10.1007/978-3-031-19032-2_3},
  doi = {10.1007/978-3-031-19032-2_3},
  abstract = {World models facilitate sample-efficient reinforcement learning (RL) and, by design, can benefit from the multitask information. However, it is not used by typical model-based RL (MBRL) agents. We propose a data-centric approach to this problem. We build a controllable optimization process for MBRL agents that selectively prioritizes the data used by the model-based agent to improve its performance. We show how this can favor implicit task generalization in a custom environment based on MetaWorld with a parametric task variability. Furthermore, by bootstrapping the agent’s data, our method can boost the performance on unstable environments from DeepMind Control Suite. This is done without any additional data and architectural changes outperforming state-of-the-art visual model-based RL algorithms. Additionally, we frame the approach within the scope of methods that have unintentionally followed the controllable optimization process paradigm, filling the gap of the data-centric task-bootstrapping methods.},
  keywords = {myconf, scopus, Reinforcement learning, frccsc, Model-based reinforcement learning, q4scopusprelim, airi, Generalization in RL, govgrant},
}

@inproceedings{Yudin2023,
  bibtex_show={true},
  abbr={ICONIP},
  html={https://link.springer.com/10.1007/978-3-031-19032-2_3},
  pdf={example_pdf.pdf},
  dimensions={true},
  selected={false},
	title = {HPointLoc: Point-based Indoor Place Recognition using Synthetic RGB-D Images},
	volume = {13625},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-30111-7_40},
	doi = {10.1007/978-3-031-30111-7_40},
	abstract = {We present a novel dataset named as HPointLoc, specially designed for exploring capabilities of visual place recognition in indoor environment and loop detection in simultaneous localization and mapping. The loop detection sub-task is especially relevant when a robot with an on-board RGB-D camera can drive past the same place (``Point") at different angles. The dataset is based on the popular Habitat simulator, in which it is possible to generate photorealistic indoor scenes using both own sensor data and open datasets, such as Matterport3D. To study the main stages of solving the place recognition problem on the HPointLoc dataset, we proposed a new modular approach named as PNTR. It first performs an image retrieval with the Patch-NetVLAD method, then extracts keypoints and matches them using R2D2, LoFTR or SuperPoint with SuperGlue, and finally performs a camera pose optimization step with TEASER++. Such a solution to the place recognition problem has not been previously studied in existing publications. The PNTR approach has shown the best quality metrics on the HPointLoc dataset and has a high potential for real use in localization systems for unmanned vehicles. The proposed dataset and framework are publicly available: https://github.com/metra4ok/HPointLoc.},
	booktitle = {Neural Information Processing. Lecture Notes in Computer Science},
	author = {Yudin, Dmitry and Solomentsev, Yaroslav and Musaev, Ruslan and Staroverov, Aleksei and Panov, Aleksandr I},
	editor = {Tanveer, Mohammad and Agarwal, Sonali and Ozawa, Seiichi and Ekbal, Asif and Jatowt, Adam},
	year = {2023},
	keywords = {dataset, indoor localization, rgb-d image, synthetic, visual place recognition},
	pages = {471--484}
}

@article{Staroverov2023,
  bibtex_show={true},
  abbr={Robotics},
  html={https://www.mdpi.com/2218-6581/12/4/104},
  pdf={example_pdf.pdf},
  dimensions={true},
  selected={true},
	title = {Skill {Fusion} in {Hybrid} {Robotic} {Framework} for {Visual} {Object} {Goal} {Navigation}},
	volume = {12},
	issn = {2218-6581},
	url = {https://www.mdpi.com/2218-6581/12/4/104},
	doi = {10.3390/robotics12040104},
	abstract = {In recent years, Embodied AI has become one of the main topics in robotics. For the agent to operate in human-centric environments, it needs the ability to explore previously unseen areas and to navigate to objects that humans want the agent to interact with. This task, which can be formulated as ObjectGoal Navigation (ObjectNav), is the main focus of this work. To solve this challenging problem, we suggest a hybrid framework consisting of both not-learnable and learnable modules and a switcher between them—SkillFusion. The former are more accurate, while the latter are more robust to sensors’ noise. To mitigate the sim-to-real gap, which often arises with learnable methods, we suggest training them in such a way that they are less environment-dependent. As a result, our method showed top results in both the Habitat simulator and during the evaluations on a real robot. Video and code for our approach can be found on our website: https://github.com/AIRI-Institute/skill-fusion (accessed on 13 July 2023).},
	journal = {Robotics},
	author = {Staroverov, Aleksei and Muravyev, Kirill and Yakovlev, Konstantin and Panov, Aleksandr I},
	year = {2023},
}

@inproceedings{Ugadiarov2023,
  bibtex_show={true},
  abbr={IJCAI},
  pdf={example_pdf.pdf},
  dimensions={true},
  selected={false},
	title = {Object-{Oriented} {Decomposition} of {World} {Model} in {Reinforcement} {Learning}},
	abstract = {Object-oriented models are expected to have better generalization abilities and operate on a more compact state representation. Recent studies have shown that using pre-trained object-centric representation learning models for state factorization in model-free algorithms improves the efficiency of policy learning. Approaches using object-factored world models to predict the environment dynamics have also shown their effectiveness in object-based grid-world environments. Following those works, we propose a novel object-oriented model-based value-based reinforcement learning algorithm Object Oriented Q-network (OOQN) employing an object-oriented decomposition of the world and state-value models. The results of the experiments demonstrate that the developed algorithm outperforms state-of-the-art model-free policy gradient algorithms and model-based value-based algorithm with a monolithic world model in tasks where individual dynamics of the objects is similar.},
	booktitle = {IJCAI Neuro-Symbolic Agents Workshop},
	author = {Ugadiarov, Leonid and Panov, Aleksandr I},
	year = {2023}
}

@inproceedings{Zemskova2023,
  bibtex_show={true},
  abbr={CVPR},
  pdf={example_pdf.pdf},
  dimensions={true},
  selected={false},
	title = {SegmATRon: Embodied Adaptive Semantic Segmentation for Indoor Environment},
	abstract = {This paper presents an adaptive transformer model named SegmATRon for embodied image semantic segmentation. Its distinctive feature is the adaptation of model weights during inference on several images using a hybrid multicomponent loss function. We studied this model on datasets collected in the photorealistic Habitat Simulator. We showed that obtaining additional images using the agent’s actions in an indoor environment can improve the quality of semantic segmentation.},
	booktitle = {CVPR Workshop on Embodied AI},
	author = {Zemskova, Tatiana and Kichik, Margarita and Yudin, Dmitry and Panov, Aleksandr},
	year = {2023}
}
