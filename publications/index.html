<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Aleksandr I. Panov</title> <meta name="author" content="Aleksandr I. Panov"> <meta name="description" content="Personal page of Aleksandr I. Panov "> <meta name="keywords" content="artificial intelligence, reinforcement learning, planning, multi-agent systems, visual navigation, cognitive robotics"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://grafft.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Aleksandr I. Panov</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item active"> <a class="nav-link" href="/ru/publications/"> RU </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">TNNLS</abbr></div> <div id="Skrynnik2023" class="col-sm-8"> <div class="title">When to Switch: Planning and Learning For Partially Observable Multi-Agent Pathfinding</div> <div class="author"> Alexey Skrynnik, Anton Andreychuk, <a href="http://kyakovlev.me/ru/home/" rel="external nofollow noopener" target="_blank">Konstantin Yakovlev</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Aleksandr Panov' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>IEEE Transactions on Neural Networks and Learning Systems</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/switcher2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/TNNLS.2023.3303502" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Skrynnik2023</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{When to Switch: Planning and Learning For Partially Observable Multi-Agent Pathfinding}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TNNLS.2023.3303502}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{(In Press)}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{IEEE} Transactions on Neural Networks and Learning Systems}</span><span class="p">,</span>
  <span class="na">shortjournal</span> <span class="p">=</span> <span class="s">{{TNNLS}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Skrynnik, Alexey and Andreychuk, Anton and Yakovlev, Konstantin and Panov, Aleksandr}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{appl, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">RAL</abbr></div> <div id="Angulo2023" class="col-sm-8"> <div class="title">Policy Optimization to Learn Adaptive Motion Primitives in Path Planning With Dynamic Obstacles</div> <div class="author"> Brian Angulo, <em>Aleksandr Panov</em>, and <a href="http://kyakovlev.me/ru/home/" rel="external nofollow noopener" target="_blank">Konstantin Yakovlev</a> </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/polamp2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/LRA.2022.3233261" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>This paper addresses the kinodynamic motion planning for non-holonomic robots in dynamic environments with both static and dynamic obstacles – a challenging problem that lacks a universal solution yet. One of the promising approaches to solve it is decomposing the problem into the smaller sub-problems and combining the local solutions into the global one. The crux of any planning method for non- holonomic robots is the generation of motion primitives that generates solutions to local planning sub-problems. In this work we introduce a novel learnable steering function (policy), which takes into account kinodynamic constraints of the robot and both static and dynamic obstacles. This policy is efficiently trained via the policy optimization. Empirically, we show that our steering function generalizes well to unseen problems. We then plug in the trained policy into the sampling-based and lattice-based planners, and evaluate the resultant POLAMP algorithm (Policy Optimization that Learns Adaptive Motion Primitives) in a range of challenging setups that involve a car-like robot operating in the obstacle-rich parking-lot en- vironments. We show that POLAMP is able to plan collision- free kinodynamic trajectories with success rates higher than 92%, when 50 simultaneously moving obstacles populate the environment showing better performance than the state-of-the- art competitors.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Angulo2023</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Policy Optimization to Learn Adaptive Motion Primitives in Path Planning With Dynamic Obstacles}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2377-3766}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/10003648/}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/LRA.2022.3233261}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{824--831}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{IEEE} Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Angulo, Brian and Panov, Aleksandr and Yakovlev, Konstantin}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2212.14307}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{robotics, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeuroInfo</abbr></div> <div id="Zholus2023" class="col-sm-8"> <div class="title">Addressing Task Prioritization in Model-based Reinforcement Learning</div> <div class="author"> Artem Zholus, Yaroslav Ivchenkov, and Aleksandr I Panov</div> <div class="periodical"> <em>In Advances in Neural Computation, Machine Learning, and Cognitive Research VI. NEUROINFORMATICS 2022. Studies in Computational Intelligence</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/10.1007/978-3-031-19032-2_3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/tapig2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-031-19032-2_3" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>World models facilitate sample-efficient reinforcement learning (RL) and, by design, can benefit from the multitask information. However, it is not used by typical model-based RL (MBRL) agents. We propose a data-centric approach to this problem. We build a controllable optimization process for MBRL agents that selectively prioritizes the data used by the model-based agent to improve its performance. We show how this can favor implicit task generalization in a custom environment based on MetaWorld with a parametric task variability. Furthermore, by bootstrapping the agent’s data, our method can boost the performance on unstable environments from DeepMind Control Suite. This is done without any additional data and architectural changes outperforming state-of-the-art visual model-based RL algorithms. Additionally, we frame the approach within the scope of methods that have unintentionally followed the controllable optimization process paradigm, filling the gap of the data-centric task-bootstrapping methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Zholus2023</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Addressing {Task} {Prioritization} in {Model}-based {Reinforcement} {Learning}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Computation, Machine Learning, and Cognitive Research VI. NEUROINFORMATICS 2022. Studies in Computational Intelligence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zholus, Artem and Ivchenkov, Yaroslav and Panov, Aleksandr I}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Kryzhanovsky, B. and Dunin-Barkowski, W. and Redko, V. and Tiumentsev, Y.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{19--30}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{1064}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-031-19031-5}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/10.1007/978-3-031-19032-2_3}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-031-19032-2_3}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{myconf, scopus, Reinforcement learning, frccsc, Model-based reinforcement learning, q4scopusprelim, airi, Generalization in RL, govgrant}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICONIP</abbr></div> <div id="Yudin2023" class="col-sm-8"> <div class="title">HPointLoc: Point-based Indoor Place Recognition using Synthetic RGB-D Images</div> <div class="author"> Dmitry Yudin, Yaroslav Solomentsev, Ruslan Musaev, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Aleksei Staroverov, Aleksandr I Panov' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Neural Information Processing. Lecture Notes in Computer Science</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/10.1007/978-3-031-19032-2_3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/hpointloc2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-031-30111-7_40" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>We present a novel dataset named as HPointLoc, specially designed for exploring capabilities of visual place recognition in indoor environment and loop detection in simultaneous localization and mapping. The loop detection sub-task is especially relevant when a robot with an on-board RGB-D camera can drive past the same place (“Point") at different angles. The dataset is based on the popular Habitat simulator, in which it is possible to generate photorealistic indoor scenes using both own sensor data and open datasets, such as Matterport3D. To study the main stages of solving the place recognition problem on the HPointLoc dataset, we proposed a new modular approach named as PNTR. It first performs an image retrieval with the Patch-NetVLAD method, then extracts keypoints and matches them using R2D2, LoFTR or SuperPoint with SuperGlue, and finally performs a camera pose optimization step with TEASER++. Such a solution to the place recognition problem has not been previously studied in existing publications. The PNTR approach has shown the best quality metrics on the HPointLoc dataset and has a high potential for real use in localization systems for unmanned vehicles. The proposed dataset and framework are publicly available: https://github.com/metra4ok/HPointLoc.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Yudin2023</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{HPointLoc: Point-based Indoor Place Recognition using Synthetic RGB-D Images}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13625}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/chapter/10.1007/978-3-031-30111-7_40}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-031-30111-7_40}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Neural Information Processing. Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yudin, Dmitry and Solomentsev, Yaroslav and Musaev, Ruslan and Staroverov, Aleksei and Panov, Aleksandr I}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Tanveer, Mohammad and Agarwal, Sonali and Ozawa, Seiichi and Ekbal, Asif and Jatowt, Adam}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{dataset, indoor localization, rgb-d image, synthetic, visual place recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{471--484}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#00369f"><a href="https://www.mdpi.com/journal/robotics/" rel="external nofollow noopener" target="_blank">Robotics</a></abbr></div> <div id="Staroverov2023" class="col-sm-8"> <div class="title">Skill Fusion in Hybrid Robotic Framework for Visual Object Goal Navigation</div> <div class="author"> Aleksei Staroverov, Kirill Muravyev, <a href="http://kyakovlev.me/ru/home/" rel="external nofollow noopener" target="_blank">Konstantin Yakovlev</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Aleksandr I Panov' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Robotics</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.mdpi.com/2218-6581/12/4/104" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/robotics2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.3390/robotics12040104" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In recent years, Embodied AI has become one of the main topics in robotics. For the agent to operate in human-centric environments, it needs the ability to explore previously unseen areas and to navigate to objects that humans want the agent to interact with. This task, which can be formulated as ObjectGoal Navigation (ObjectNav), is the main focus of this work. To solve this challenging problem, we suggest a hybrid framework consisting of both not-learnable and learnable modules and a switcher between them—SkillFusion. The former are more accurate, while the latter are more robust to sensors’ noise. To mitigate the sim-to-real gap, which often arises with learnable methods, we suggest training them in such a way that they are less environment-dependent. As a result, our method showed top results in both the Habitat simulator and during the evaluations on a real robot. Video and code for our approach can be found on our website: https://github.com/AIRI-Institute/skill-fusion (accessed on 13 July 2023).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Staroverov2023</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Skill {Fusion} in {Hybrid} {Robotic} {Framework} for {Visual} {Object} {Goal} {Navigation}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2218-6581}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.mdpi.com/2218-6581/12/4/104}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3390/robotics12040104}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Robotics}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Staroverov, Aleksei and Muravyev, Kirill and Yakovlev, Konstantin and Panov, Aleksandr I}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IJCAI</abbr></div> <div id="Ugadiarov2023" class="col-sm-8"> <div class="title">Object-Oriented Decomposition of World Model in Reinforcement Learning</div> <div class="author"> Leonid Ugadiarov, and Aleksandr I Panov</div> <div class="periodical"> <em>In IJCAI Neuro-Symbolic Agents Workshop</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ooqn2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Object-oriented models are expected to have better generalization abilities and operate on a more compact state representation. Recent studies have shown that using pre-trained object-centric representation learning models for state factorization in model-free algorithms improves the efficiency of policy learning. Approaches using object-factored world models to predict the environment dynamics have also shown their effectiveness in object-based grid-world environments. Following those works, we propose a novel object-oriented model-based value-based reinforcement learning algorithm Object Oriented Q-network (OOQN) employing an object-oriented decomposition of the world and state-value models. The results of the experiments demonstrate that the developed algorithm outperforms state-of-the-art model-free policy gradient algorithms and model-based value-based algorithm with a monolithic world model in tasks where individual dynamics of the objects is similar.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Ugadiarov2023</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Object-{Oriented} {Decomposition} of {World} {Model} in {Reinforcement} {Learning}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IJCAI Neuro-Symbolic Agents Workshop}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ugadiarov, Leonid and Panov, Aleksandr I}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CVPR</abbr></div> <div id="Zemskova2023" class="col-sm-8"> <div class="title">SegmATRon: Embodied Adaptive Semantic Segmentation for Indoor Environment</div> <div class="author"> Tatiana Zemskova, Margarita Kichik, Dmitry Yudin, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Aleksandr Panov' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In CVPR Workshop on Embodied AI</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/segmatron2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>This paper presents an adaptive transformer model named SegmATRon for embodied image semantic segmentation. Its distinctive feature is the adaptation of model weights during inference on several images using a hybrid multicomponent loss function. We studied this model on datasets collected in the photorealistic Habitat Simulator. We showed that obtaining additional images using the agent’s actions in an indoor environment can improve the quality of semantic segmentation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Zemskova2023</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SegmATRon: Embodied Adaptive Semantic Segmentation for Indoor Environment}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CVPR Workshop on Embodied AI}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zemskova, Tatiana and Kichik, Margarita and Yudin, Dmitry and Panov, Aleksandr}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Doklady</abbr></div> <div id="Kovalev2022" class="col-sm-8"> <div class="title">Application of Pretrained Large Language Models in Embodied Artificial Intelligence</div> <div class="author"> A. K. Kovalev, and Aleksandr I. Panov</div> <div class="periodical"> <em>Doklady Mathematics</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/embodied2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1134/S1064562422060138" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>A feature of tasks in embodied artificial intelligence is that a query to an intelligent agent is formulated in natural language. As a result, natural language processing methods have to be used to transform the query into a format convenient for generating an appropriate action plan. There are two basic approaches to the solution of this problem. One is based on specialized models trained with particular instances of instructions translated into agent-executable format. The other approach relies on the ability of large language models trained with a large amount of unlabeled data to store common sense knowledge. As a result, such models can be used to generate an agent’s action plan in natural language without preliminary learning. This paper provides a detailed review of models based on the second approach as applied to embodied artificial intelli- gence tasks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Kovalev2022</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Application of Pretrained Large Language Models in Embodied Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{106}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1064-5624}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/10.1134/S1064562422060138}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1134/S1064562422060138}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{S85--S90}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{S1}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Doklady Mathematics}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kovalev, A. K. and Panov, Aleksandr I.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{slpa, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">BrainInf</abbr></div> <div id="Dzhivelikian2022a" class="col-sm-8"> <div class="title">Hierarchical intrinsically motivated agent planning behavior with dreaming in grid environments</div> <div class="author"> Evgenii Dzhivelikian, Artem Latyshev, Petr Kuderov, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Aleksandr I Panov' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Brain Informatics</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/hima2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1186/s40708-022-00156-6" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Biologically plausible models of learning may provide a crucial insight for building autonomous intelligent agents capable of performing a wide range of tasks. In this work, we propose a hierarchical model of an agent operating in an unfamiliar environment driven by a reinforcement signal. We use temporal memory to learn sparse distributed representation of state–actions and the basal ganglia model to learn effective action policy on different levels of abstraction. The learned model of the environment is utilized to generate an intrinsic motivation signal, which drives the agent in the absence of the extrinsic signal, and through acting in imagination, which we call dreaming. We demonstrate that the proposed architecture enables an agent to effectively reach goals in grid environments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Dzhivelikian2022a</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hierarchical intrinsically motivated agent planning behavior with dreaming in grid environments}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2198-4018}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://braininformatics.springeropen.com/articles/10.1186/s40708-022-00156-6}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1186/s40708-022-00156-6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Brain Informatics}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dzhivelikian, Evgenii and Latyshev, Artem and Kuderov, Petr and Panov, Aleksandr I}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{slap, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Doklady</abbr></div> <div id="Yakovkev2022" class="col-sm-8"> <div class="title">Planning and Learning in Multi-Agent Path Finding</div> <div class="author"> <a href="http://kyakovlev.me/ru/home/" rel="external nofollow noopener" target="_blank">K. S. Yakovlev</a>, A. A. Andreychuk, A. A. Skrynnik, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Aleksandr I. Panov' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Doklady Mathematics</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/marlp2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1134/S1064562422060229" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Multi-agent path finding arises, on the one hand, in numerous applied areas. A classical example is automated warehouses with a large number of mobile goods-sorting robots operating simultaneously. On the other hand, for this problem, there are no universal solution methods that simultaneously satisfy numerous (often contradictory) requirements. Examples of such criteria are a guarantee of finding optimal solu- tions, high-speed operation, the possibility of operation in partially observable environments, etc. This paper provides a survey of modern methods for multi-agent path finding. Special attention is given to various settings of the problem. The differences and between trainable and nontrainable solution methods and their applicability are discussed. Experimental programming environments necessary for implementing trainable approaches are analyzed separately.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Yakovkev2022</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Planning and Learning in Multi-Agent Path Finding}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{106}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1064-5624}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/10.1134/S1064562422060229}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1134/S1064562422060229}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{S79--S84}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{S1}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Doklady Mathematics}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yakovlev, K. S. and Andreychuk, A. A. and Skrynnik, A. A. and Panov, Aleksandr I.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{appl, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">PeerJ</abbr></div> <div id="Skrynnik2022a" class="col-sm-8"> <div class="title">Pathfinding in stochastic environments: learning vs planning</div> <div class="author"> Alexey Skrynnik, Anton Andreychuk, <a href="http://kyakovlev.me/ru/home/" rel="external nofollow noopener" target="_blank">Konstantin Yakovlev</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Aleksandr Panov' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>PeerJ Computer Science</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/peerj2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.7717/peerj-cs.1056" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Among the main challenges associated with navigating a mobile robot in complex environments are partial observability and stochasticity. This work proposes a stochastic formulation of the pathfinding problem, assuming that obstacles of arbitrary shapes may appear and disappear at random moments of time. Moreover, we consider the case when the environment is only partially observable for an agent. We study and evaluate two orthogonal approaches to tackle the problem of reaching the goal under such conditions: planning and learning. Within planning, an agent constantly re-plans and upyears the path based on the history of the observations using a search-based planner. Within learning, an agent asynchronously learns to optimize a policy function using recurrent neural networks (we propose an original efficient, scalable approach). We carry on an extensive empirical evaluation of both approaches that show that the learning-based approach scales better to the increasing number of the unpredictably appearing/disappearing obstacles. At the same time, the planning-based one is preferable when the environment is close-to-the-deterministic ( i.e. , external disturbances are rare). Code available at https://github.com/Tviskaron/pathfinding-in-stochastic-envs .</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Skrynnik2022a</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pathfinding in stochastic environments: learning vs planning}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2376-5992}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://peerj.com/articles/cs-1056}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.7717/peerj-cs.1056}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{e1056}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{PeerJ} Computer Science}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Skrynnik, Alexey and Andreychuk, Anton and Yakovlev, Konstantin and Panov, Aleksandr}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{appl, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://ieeeaccess.ieee.org/" rel="external nofollow noopener" target="_blank">Access</a></abbr></div> <div id="Staroverov2022" class="col-sm-8"> <div class="title">Hierarchical Landmark Policy Optimization for Visual Indoor Navigation</div> <div class="author"> Aleksei Staroverov, and <em>Aleksandr Panov</em> </div> <div class="periodical"> <em>IEEE Access</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/lppo2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/ACCESS.2022.3182803" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In this paper, we study the problem of visual indoor navigation to an object that is defined by its semantic category. Recent works have shown significant achievements in the end-to-end reinforcement learning approach and modular systems. However, both approaches need a big step forward to be robust and practically applicable. To solve the problem of insufficient exploration of the scenes and make exploration more semantically meaningful, we extend standard task formulation and give the agent easily accessible landmarks in the form of the room locations and those types. The availability of landmarks allows the agent to build a hierarchical policy structure and achieve a success rate of 63% on validation scenes in a photo- realistic Habitat simulator. In a hierarchy, a low level consists of separately trained RL skills and a high level deterministic policy, which decides which skill is needed at the moment. Also, in this paper, we show the possibility of transferring a trained policy to a real robot. After a bit of training on the reconstructed real scene, the robot shows up to 79% SPL when solving the task of navigating to an arbitrary object.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Staroverov2022</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hierarchical Landmark Policy Optimization for Visual Indoor Navigation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2169-3536}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/9795006/}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2022.3182803}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{70447--70455}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{IEEE} Access}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Staroverov, Aleksei and Panov, Aleksandr}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{robotics, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LNCS</abbr></div> <div id="Ugadiarov2021" class="col-sm-8"> <div class="title">Long-Term Exploration in Persistent MDPs</div> <div class="author"> Leonid Ugadiarov, Alexey Skrynnik, and Aleksandr I. Panov</div> <div class="periodical"> <em>In Advances in Soft Computing. MICAI 2021. Part I. Lecture Notes in Computer Science</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/explore2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-030-89817-5_8" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Exploration is an essential part of reinforcement learning, which restricts the quality of learned policy. Hard-exploration environments are defined by huge state space and sparse rewards. In such conditions, an exhaustive exploration of the environment is often impossible, and the successful training of an agent requires a lot of interaction steps. In this paper, we propose an exploration method called Rollback-Explore (RbExplore), which utilizes the concept of the persistent Markov decision process, in which agents during training can roll back to visited states. We test our algorithm in the hard-exploration Prince of Persia game, without rewards and domain knowledge. At all used levels of the game, our agent outperforms or shows comparable results with state-of-the-art curiosity methods with knowledge-based intrinsic motivation: ICM and RND. An implementation of RbExplore can be found at https://github.com/cds-mipt/RbExplore.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">Ugadiarov2021</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Long-Term Exploration in Persistent {MDPs}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13067}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-030-89817-5}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{108--120}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Soft Computing. {MICAI} 2021. Part I. Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ugadiarov, Leonid and Skrynnik, Alexey and Panov, Aleksandr I.}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Batyrshin, Ildar and Gelbukh, Alexander and Sidorov, Grigori}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2109.10173}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-89817-5_8}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{slap, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LNCS</abbr></div> <div id="Rak2021" class="col-sm-8"> <div class="title">Flexible Data Augmentation in Off-Policy Reinforcement Learning</div> <div class="author"> Alexandra Rak, Alexey Skrynnik, and Aleksandr I Panov</div> <div class="periodical"> <em>In Artificial Intelligence and Soft Computing. ICAISC 2021. Lecture Notes in Computer Science</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/augment2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-030-87986-0_20" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>This paper explores an application of image augmentation in reinforcement learning tasks - a popular regularization technique in the computer vision area. The analysis is based on the model-free off-policy algorithms. As a regularization, we consider the augmentation of the frames that are sampled from the replay buffer of the model. Evaluated augmentation techniques are random changes in image contrast, random shifting, random cutting, and others. Research is done using the environments of the Atari games: Breakout, Space Invaders, Berzerk, Wizard of Wor, Demon Attack. Using augmentations allowed us to obtain results confirming the significant acceleration of the model’s algorithm convergence. We also proposed an adaptive mechanism for selecting the type of augmentation depending on the type of task being performed by the agent.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">Rak2021</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Flexible Data Augmentation in Off-Policy Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12854}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.scopus.com/record/display.uri?eid=2-s2.0-85117454790&amp;origin=resultslist}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{224--235}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Artificial Intelligence and Soft Computing. {ICAISC} 2021. Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer, Cham}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rak, Alexandra and Skrynnik, Alexey and Panov, Aleksandr I}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Rutkowski, L.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-87986-0_20}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{slpa, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">KBS</abbr></div> <div id="Skrynnik2021" class="col-sm-8"> <div class="title">Forgetful experience replay in hierarchical reinforcement learning from expert demonstrations</div> <div class="author"> Alexey Skrynnik, Aleksey Staroverov, Ermek Aitygulov, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Kirill Aksenov, Vasilii Davydov, Aleksandr I. Panov' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Knowledge-Based Systems</em>, 2021 </div> <div class="periodical"> Publisher: Elsevier B.V. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/forger2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1016/j.knosys.2021.106844" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Deep reinforcement learning (RL) shows impressive results in complex gaming and robotic environments. These results are commonly achieved at the expense of huge computational costs and require an incredible number of episodes of interactions between the agent and the environment. Hierarchical methods and expert demonstrations are among the most promising approaches to improve the sample efficiency of reinforcement learning methods. In this paper, we propose a combination of methods that allow the agent to use low-quality demonstrations in complex vision-based environments with multiple related goals. Our Forgetful Experience Replay (ForgER) algorithm effectively handles expert data errors and reduces quality losses when adapting the action space and states representation to the agent’s capabilities. The proposed goal-oriented replay buffer structure allows the agent to automatically highlight sub-goals for solving complex hierarchical tasks in demonstrations. Our method has a high degree of versatility and can be integrated into various off-policy methods. The ForgER surpasses the existing state-of-the-art RL methods using expert demonstrations in complex environments. The solution based on our algorithm beats other solutions for the famous MineRL competition and allows the agent to demonstrate the behavior at the expert level.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Skrynnik2021</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Forgetful experience replay in hierarchical reinforcement learning from expert demonstrations}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{218}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{09507051}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://linkinghub.elsevier.com/retrieve/pii/S0950705121001076}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.knosys.2021.106844}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{106844}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Knowledge-Based Systems}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Skrynnik, Alexey and Staroverov, Aleksey and Aitygulov, Ermek and Aksenov, Kirill and Davydov, Vasilii and Panov, Aleksandr I.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Publisher: Elsevier B.V.}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{slap, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CSR</abbr></div> <div id="Skrynnik2021a" class="col-sm-8"> <div class="title">Hierarchical Deep Q-Network from imperfect demonstrations in Minecraft</div> <div class="author"> Alexey Skrynnik, Aleksey Staroverov, Ermek Aitygulov, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Kirill Aksenov, Vasilii Davydov, Aleksandr I. Panov' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Cognitive Systems Research</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/hdqfd2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1016/j.cogsys.2020.08.012" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>We present hierarchical Deep Q-Network (HDQfD) that took first place in MineRL competition. HDQfD works on imperfect demonstrations utilize hierarchical structure of expert trajectories extracting effective sequence of meta-actions and subgoals. We introduce structured task dependent replay buffer and adaptive prioritizing technique that allow the HDQfD agent to gradually erase poor-quality expert data from the buffer. In this paper we present the details of the HDQfD algorithm and give the experimental results in Minecraft domain.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Skrynnik2021a</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hierarchical Deep Q-Network from imperfect demonstrations in Minecraft}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{65}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{13890417}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S1389041720300723?via%3Dihub}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.cogsys.2020.08.012}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{74--78}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Cognitive Systems Research}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Skrynnik, Alexey and Staroverov, Aleksey and Aitygulov, Ermek and Aksenov, Kirill and Davydov, Vasilii and Panov, Aleksandr I.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{1912.08664v2}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{slap, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LNCS</abbr></div> <div id="Kovalev2021b" class="col-sm-8"> <div class="title">Applying Vector Symbolic Architecture and Semiotic Approach to Visual Dialog</div> <div class="author"> Alexey K Kovalev, Makhmud Shaban, Anfisa A. Chuganskaya, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Aleksandr I. Panov' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Hybrid Artificial Intelligent Systems. HAIS 2021. Lecture Notes in Computer Science</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/vqsa2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-030-86271-8_21" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>The multi-modal tasks have started to play a significant role in the research on Artificial Intelligence. A particular example of that domain is visual-linguistic tasks, such as Visual Question Answering and its extension, Visual Dialog. In this paper, we concentrate on the Visual Dialog task and dataset. The task involves two agents. The first agent does not see an image and asks questions about the image content. The second agent sees this image and answers questions. The symbol grounding problem, or how symbols obtain their meanings, plays a crucial role in such tasks. We approach that problem from the semiotic point of view and propose the Vector Semiotic Architecture for Visual Dialog. The Vector Semiotic Architecture is a combination of the Sign-Based World Model and Vector Symbolic Architecture. The Sign-Based World Model represents agent knowledge on the high level of abstraction and allows uniform representation of different aspects of knowledge, forming a hierarchical representation of that knowledge in the form of a special kind of semantic network. The Vector Symbolic Architecture represents the computational level and allows to operate with symbols as with numerical vectors using simple element-wise operations. That combination enables grounding object representation from any level of abstraction to the sensory agent input.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">Kovalev2021b</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Applying Vector Symbolic Architecture and Semiotic Approach to Visual Dialog}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12886}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-030-86270-1}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.scopus.com/record/display.uri?eid=2-s2.0-85115865440&amp;origin=resultslist}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{243--255}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Hybrid Artificial Intelligent Systems. {HAIS} 2021. Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kovalev, Alexey K and Shaban, Makhmud and Chuganskaya, Anfisa A. and Panov, Aleksandr I.}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{González, Hugo Sanjurjo and López, Iker Pastor and Bringa, Pablo García and Quintián, {SHéctor} and Corchado, Emilio}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-86271-8_21}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{swm, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://ieeeaccess.ieee.org/" rel="external nofollow noopener" target="_blank">Access</a></abbr></div> <div id="Skrynnik2021b" class="col-sm-8"> <div class="title">Hybrid Policy Learning for Multi-Agent Pathfinding</div> <div class="author"> Alexey Skrynnik, Alexandra Yakovleva, Vasilii Davydov, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Konstantin Yakovlev, Aleksandr I. Panov' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>IEEE Access</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/hybrid2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/ACCESS.2021.3111321" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In this work we study the behavior of groups of autonomous vehicles, which are the part of the Internet ofVehicles systems. One of the challenging modes of operation of such systems is the case when the observability of each vehicle is limited and the global/local communication is unstable, e.g. in the crowded parking lots. In such scenarios the vehicles have to rely on the local observations and exhibit cooperative behavior to ensure safe and efficient trips. This type of problems can be abstracted to the so-called multi- agent pathfinding when a group of agents, confined to a graph, have to find collision-free paths to their goals (ideally, minimizing an objective function e.g. travel time). Widely used algorithms for solving this problem rely on the assumption that a central controller exists for which the full state of the environment (i.e. the agents current positions, their targets, configuration of the static obstacles etc.) is known and they cannot be straightforwardly be adapted to the partially-observable setups. To this end, we suggest a novel approach which is based on the decomposition of the problem into the two sub-tasks: reaching the goal and avoiding the collisions. To accomplish each of this task we utilize reinforcement learning methods such as Deep Monte Carlo Tree Search, Q-mixing networks, and policy gradients methods to design the policies that map the agents’ observations to actions. Next, we introduce the policy-mixing mechanism to end up with a single hybrid policy that allows each agent to exhibit both types of behavior – the individual one (reaching the goal) and the cooperative one (avoiding the collisions with other agents). We conduct an extensive empirical evaluation that shows that the suggested hybrid-policy outperforms standalone stat-of-the-art reinforcement learning methods for this kind of problems by a notable margin.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Skrynnik2021b</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hybrid Policy Learning for Multi-Agent Pathfinding}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2169-3536}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/9532001/}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2021.3111321}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{126034--126047}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{IEEE} Access}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Skrynnik, Alexey and Yakovleva, Alexandra and Davydov, Vasilii and Yakovlev, Konstantin and Panov, Aleksandr I.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{appl, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LNCS</abbr></div> <div id="Jamal2021" class="col-sm-8"> <div class="title">Adaptive Maneuver Planning for Autonomous Vehicles Using Behavior Tree on Apollo Platform</div> <div class="author"> Mais Jamal, and <em>Aleksandr Panov</em> </div> <div class="periodical"> <em>In Artificial Intelligence XXXVIII. SGAI 2021. Lecture Notes in Computer Science</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/adaptive2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-030-91100-3_26" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In safety-critical systems such as autonomous driving sys- tems, behavior planning is a significant challenge. The presence of numerous dynamic obstacles makes the driving environment unpredictable. The planning algorithm should be safe, reactive, and adaptable to environmental changes. The paper presents an adaptive maneuver planning algorithm based on an evolving behavior tree created with genetic programming. In addition, we make a technical contribution to the Baidu Apollo autonomous driving platform, allowing the platform to test and develop overtaking maneuver planning algorithms.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">Jamal2021</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adaptive Maneuver Planning for Autonomous Vehicles Using Behavior Tree on Apollo Platform}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13101}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/10.1007/978-3-030-91100-3_26}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{327--340}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Artificial Intelligence {XXXVIII}. {SGAI} 2021. Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jamal, Mais and Panov, Aleksandr}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Bramer, Max and Ellis, Richard}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-91100-3_26}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{robotics, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LNCS</abbr></div> <div id="Davydov2021" class="col-sm-8"> <div class="title">Q-Mixing Network for Multi-agent Pathfinding in Partially Observable Grid Environments</div> <div class="author"> Vasilii Davydov, Alexey Skrynnik, <a href="http://kyakovlev.me/ru/home/" rel="external nofollow noopener" target="_blank">Konstantin Yakovlev</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Aleksandr Panov' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Artificial Intelligence. RCAI 2021. Lecture Notes in Computer Science</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/qmixpath2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-030-86855-0_12" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In this paper, we consider the problem of multi-agent navigation in partially observable grid environments. This problem is challenging for centralized planning approaches as they typically rely on full knowledge of the environment. To this end, we suggest utilizing the reinforcement learning approach when the agents first learn the policies that map observations to actions and then follow these policies to reach their goals. To tackle the challenge associated with learning cooperative behavior, i.e. in many cases agents need to yield to each other to accomplish a mission. We use a mixing Q-network that complements learning individual policies. In the experimental evaluation, we show that such approach leads to plausible results and scales well to a large number of agents.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">Davydov2021</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Q-Mixing Network for Multi-agent Pathfinding in Partially Observable Grid Environments}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12948}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-030-86854-3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{169--179}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Artificial Intelligence. {RCAI} 2021. Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Davydov, Vasilii and Skrynnik, Alexey and Yakovlev, Konstantin and Panov, Aleksandr}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Kovalev, Sergei M. and Kuznetsov, Sergei O. and Panov, Aleksandr I.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2108.06148}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-86855-0_12}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{appl, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://ieeeaccess.ieee.org/" rel="external nofollow noopener" target="_blank">Access</a></abbr></div> <div id="Staroverov2020b" class="col-sm-8"> <div class="title">Real-Time Object Navigation with Deep Neural Networks and Hierarchical Reinforcement Learning</div> <div class="author"> Aleksey Staroverov, Dmitry A. Yudin, Ilya Belkin, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Vasily Adeshkin, Yaroslav K. Solomentsev, Aleksandr I. Panov' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>IEEE Access</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/mppo2020.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/ACCESS.2020.3034524" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In the last years, deep learning and reinforcement learning methods have significantly improved mobile robots in such fields as perception, navigation, and planning. But there are still gaps in applying these methods to real robots due to the low computational efficiency of recent neural network architectures and their poor adaptability to robotic experiments’ realities. In this paper, we consider an important task in mobile robotics - navigation to an object using an RGB-D camera.We develop a new neural network framework for robot control that is fast and resistant to possible noise in sensors and actuators. We propose an original integration of semantic segmentation, mapping, localization, and reinforcement learning methods to improve the effectiveness of exploring the environment, finding the desired object, and quickly navigating to it. We created a new HISNav dataset based on the Habitat virtual environment, which allowed us to use simulation experiments to pre-train the model and then upload it to a real robot. Our architecture is adapted to work in a real-time environment and fully implements modern trends in this area.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Staroverov2020b</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Real-Time Object Navigation with Deep Neural Networks and Hierarchical Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2169-3536}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/9241850/}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2020.3034524}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{195608--195621}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{IEEE} Access}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Staroverov, Aleksey and Yudin, Dmitry A. and Belkin, Ilya and Adeshkin, Vasily and Solomentsev, Yaroslav K. and Panov, Aleksandr I.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{robotics, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LNCS</abbr></div> <div id="Kovalev2019" class="col-sm-8"> <div class="title">Mental Actions and Modelling of Reasoning in Semiotic Approach to AGI</div> <div class="author"> Alexey K Kovalev, and Aleksandr I Panov</div> <div class="periodical"> <em>In Artificial General Intelligence. AGI 2019. Lecture Notes in Computer Science</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/mental2019.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-030-27005-6_12" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>The article expounds the functional of a cognitive architecture Sign-Based World Model (SBWM) through the algorithm for the implementation of a particular case of reasoning. The SBWM architecture is a multigraph, called a semiotic network with special rules of activation spreading. In a semiotic network, there are four subgraphs that have specific properties and are composed of constituents of the main SBWM element – the sign. Such subgraphs are called causal networks on images, significances, personal meanings, and names. The semiotic network can be viewed as the memory of an intelligent agent. It is proposed to divide the agent’s memory in the SBWM architecture into a long-term memory consisting of signs-prototype, and a working memory consisting of signs-instance. The concept of elementary mental actions is introduced as an integral part of the reasoning process. Examples of such actions are provided. The performance of the proposed reasoning algorithm is considered by a model example.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Kovalev2019</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mental Actions and Modelling of Reasoning in Semiotic Approach to {AGI}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11654}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-030-27005-6}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/chapter/10.1007/978-3-030-27005-6_12}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-27005-6_12}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{121--131}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Artificial General Intelligence. {AGI} 2019. Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kovalev, Alexey K and Panov, Aleksandr I}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Hammer, Patrick and Agrawal, Pulin and Goertzel, Ben and Iklé, Matthew}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{swm, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LNCS</abbr></div> <div id="Kiselev2019" class="col-sm-8"> <div class="title">Hierarchical Psychologically Inspired Planning for Human-Robot Interaction Tasks</div> <div class="author"> Gleb Kiselev, and <em>Aleksandr Panov</em> </div> <div class="periodical"> <em>In Interactive Collaborative Robotics. ICR 2019. Lecture Notes in Computer Science</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/hhri2019.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-030-26118-4_15" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>This paper presents a new algorithm for hierarchical case-based behavior planning in a coalition of agents – HierMAP. The considered algorithm, in contrast to the well-known planners HEART, PANDA, and others, is intended primarily for use in multi-agent tasks. For this, the possibility of dynamically distributing agent roles with different functionalities was realized. The use of a psychologically plausible approach to the representation of the knowledge by agents using a semiotic network allows applying HierMAP in groups in which people participate as one of the actors. Thus, the algorithm allows us to represent solutions of collaborative problems, forming human- interpretable results at each planning step. Another advantage of the proposed method is the ability to save and reuse experience of planning – expansion in the field of case-based planning. Such extension makes it possible to consider information about the success/ failure of interaction with other members of the coalition. Presenting precedents as a special part of the agent’s memory (semantic network on meanings) allows to significantly reduce the planning time for a similar class of tasks. The paper deals with smart relocation tasks in the environment. A comparison is made with the main hierarchical planners widely used at present.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Kiselev2019</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hierarchical Psychologically Inspired Planning for Human-Robot Interaction Tasks}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11659}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-030-26118-4}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-030-26118-4_15}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-26118-4_15}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{150--160}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Interactive Collaborative Robotics. {ICR} 2019. Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kiselev, Gleb and Panov, Aleksandr}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Ronzhin, Andrey and Rigoll, Gerhard and Meshcheryakov, Roman}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{swm, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">STIP</abbr></div> <div id="Panov2019" class="col-sm-8"> <div class="title">Goal Setting and Behavior Planning for Cognitive Agents</div> <div class="author"> Aleksandr I. Panov</div> <div class="periodical"> <em>Scientific and Technical Information Processing</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/goalset.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.3103/S0147688219060066" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Panov2019</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Goal Setting and Behavior Planning for Cognitive Agents}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{46}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/article/10.3103/S0147688219060066}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3103/S0147688219060066}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{404--415}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scientific and Technical Information Processing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Panov, Aleksandr I.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{swm, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">OMNN</abbr></div> <div id="Yudin2019" class="col-sm-8"> <div class="title">Object Detection with Deep Neural Networks for Reinforcement Learning in the Task of Autonomous Vehicles Path Planning at the Intersection</div> <div class="author"> D A Yudin, A Skrynnik, A Krishtopik, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'I Belkin, Aleksandr I. Panov' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Optical Memory and Neural Networks</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/crossdet2019.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.3103/S1060992X19040118" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Among a number of problems in the behavior planning of an unmanned vehicle the central one is movement in difficult areas. In particular, such areas are intersections at which direct interac- tion with other road agents takes place. In our work, we offer a new approach to train of the intelligent agent that simulates the behavior of an unmanned vehicle, based on the integration of reinforcement learning and computer vision. Using full visual information about the road intersection obtained from aerial photographs, it is studied automatic detection the relative positions of all road agents with vari- ous architectures of deep neural networks (YOLOv3, Faster R-CNN, RetinaNet, Cascade R-CNN, Mask R-CNN, Cascade Mask R-CNN). The possibilities of estimation of the vehicle orientation angle based on a convolutional neural network are also investigated. Obtained additional features are used in the modern effective reinforcement learning methods of Soft Actor Critic and Rainbow, which allows to accelerate the convergence of its learning process. To demonstrate the operation of the devel- oped system, an intersection simulator was developed, at which a number of model experiments were carried out.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Yudin2019</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Object Detection with Deep Neural Networks for Reinforcement Learning in the Task of Autonomous Vehicles Path Planning at the Intersection}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{28}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1060-992X}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/article/10.3103%2FS1060992X19040118}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3103/S1060992X19040118}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{283--295}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Optical Memory and Neural Networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yudin, D A and Skrynnik, A and Krishtopik, A and Belkin, I and Panov, Aleksandr I.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{robotics, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LNCS</abbr></div> <div id="Younes2019" class="col-sm-8"> <div class="title">Toward Faster Reinforcement Learning for Robotics : Using Gaussian Processes</div> <div class="author"> Ali Younes, and Aleksandr I Panov</div> <div class="periodical"> <em>In RAAI Summer School 2019. Lecture Notes in Computer Science</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/faster2019.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-030-33274-7_11" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Standard robotic control works perfectly in case of ordinary conditions, but in the case of a change in the conditions (e.g. damaging of one of the motors), the robot won’t achieve its task anymore. We need an algorithm that provide the robot with the ability of adaption to unforeseen situations. Reinforcement learning provide a framework corresponds with that requirements, but it needs big data sets to learn robotic tasks, which is impractical. We discuss using Gaussian processes to improve the efficiency of the Reinforcement learning, where a Gaussian Process will learn a state transition model using data from the robot (interaction) phase, and after that use the learned GP model to simulate trajectories and optimize the robot’s controller in a (simulation) phase. PILCO algorithm considered as the most data efficient RL algorithm. It gives promising results in Cart-pole task, where a working controller was learned after seconds of (interaction) on the real robot, but the whole training time, considering the training in the (simulation) was longer. In this work, we will try to leverage the abilities of the computational graphs to produce a ROS friendly python implementation of PILCO, and discuss a case study of a real world robotic task.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">Younes2019</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Toward Faster Reinforcement Learning for Robotics : Using Gaussian Processes}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11866}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/chapter/10.1007%2F978-3-030-33274-7_11}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{160--174}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{RAAI} Summer School 2019. Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Younes, Ali and Panov, Aleksandr I}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Osipov, Gennady S. and Panov, Aleksandr I. and Yakovlev, Konstantin S.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-33274-7_11}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{robotics, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LNCS</abbr></div> <div id="Kiselev2018c" class="col-sm-8"> <div class="title">Task and Spatial Planning by the Cognitive Agent with Human-like Knowledge Representation</div> <div class="author"> Ermek Aitygulov, Gleb Kiselev, and Aleksandr I. Panov</div> <div class="periodical"> <em>In Interactive Collaborative Robotics. ICR 2018. Lecture Notes in Computer Science</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/qtamp2018.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-319-99582-3_1" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>The paper considers the task of simultaneous learning and planning actions for moving a cognitive agent in two-dimensional space. Planning is carried out by an agent who uses an anthropic way of knowledge representation that allows him to build transparent and understood planes, which is especially important in case of human-machine interaction. Learning actions to manipulate objects is carried out through reinforcement learning and demonstrates the possibilities of replenishing the agent’s procedural knowledge. The presented approach was demonstrated in an experiment in the Gazebo simulation environment.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Kiselev2018c</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Task and Spatial Planning by the Cognitive Agent with Human-like Knowledge Representation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11097}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-319-99582-3}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/chapter/10.1007/978-3-319-99582-3_1}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-99582-3_1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--12}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Interactive Collaborative Robotics. {ICR} 2018. Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Aitygulov, Ermek and Kiselev, Gleb and Panov, Aleksandr I.}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Ronzhin, A. and Rigoll, G. and Meshcheryakov, R.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{slap, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LNCS</abbr></div> <div id="Kiselev2017a" class="col-sm-8"> <div class="title">Synthesis of the Behavior Plan for Group of Robots with Sign Based World Model</div> <div class="author"> Gleb A. Kiselev, and Aleksandr I. Panov</div> <div class="periodical"> <em>In Interactive Collaborative Robotics. ICR 2017. Lecture Notes in Computer Science</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/grouplan2017.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-319-66471-2_10" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>The paper considers the task of the group’s collective plan intellectual agents. Robotic systems are considered as agents, possessing a manipulator and acting with objects in a determined external environment. The MultiMAP planning algorithm proposed in the article is hierarchical. It is iterative and based on the original sign representation of knowledge about objects and processes, agents knowledge about themselfs and about other members of the group. For distribution actions between agents in general plan signs “I” and “Other” (“They”) are used. In conclusion, the results of experiments in the model problem “Blocksworld” for a group of several agents are presented.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Kiselev2017a</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Synthesis of the Behavior Plan for Group of Robots with Sign Based World Model}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{10459}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-319-66470-5}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/chapter/10.1007/978-3-319-66471-2_10}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-66471-2_10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{83--94}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Interactive Collaborative Robotics. {ICR} 2017. Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kiselev, Gleb A. and Panov, Aleksandr I.}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Ronzhin, A. and Rigoll, G. and Meshcheryakov, R.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{robotics, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CSR</abbr></div> <div id="Emelyanov2016" class="col-sm-8"> <div class="title">Multilayer cognitive architecture for UAV control</div> <div class="author"> Stanislav Emel’yanov, Dmitry Makarov, Aleksandr I. Panov, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Konstantin Yakovlev' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Cognitive Systems Research</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/strl2016.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1016/j.cogsys.2015.12.008" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Extensive use of unmanned aerial vehicles (UAVs) in recent years has induced the rapid growth of research areas related to UAV production. Among these, the design of control systems capable of automating a wide range of UAV activities is one of the most actively explored and evolving. Currently, researchers and developers are interested in designing control systems that can be referred to as intelligent, e.g. the systems which are suited to solve such tasks as planning, goal prioritization, coalition formation etc. and thus guarantee high levels of UAV autonomy. One of the principal problems in intelligent control system design is tying together various methods and models traditionally used in robotics and aimed at solving such tasks as dynamics modelling, control signal genera- tion, location and mapping, path planning etc. with the methods of behaviour modelling and planning which are thoroughly studied in cognitive science. Our work is aimed at solving this problem. We propose layered architecture — STRL (strategic, tactical, reactive, layered) — of the control system that au- tomates the behaviour generation using a cognitive approach while taking into account complex dynamics and kinematics of the control object (UAV).We use a special type of knowledge representation — sign world model — that is based on the psychological activity theory to describe individual behaviour planning and coalition formation processes. We also propose path planning methodology which serves as the mediator between the high-level cognitive activities and the reactive control signals generation. To generate these signals we use a state-dependent Riccati equation and specific method for solving it. We believe that utilization of the proposed architecture will broaden the spectrum of tasks which can be solved by the UAV’s coalition automatically, as well as raise the autonomy level of each individual member of that coalition.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Emelyanov2016</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multilayer cognitive architecture for {UAV} control}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{39}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1389-0417}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://linkinghub.elsevier.com/retrieve/pii/S1389041716000048}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.cogsys.2015.12.008}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{58--72}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Cognitive Systems Research}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Emel’yanov, Stanislav and Makarov, Dmitry and Panov, Aleksandr I. and Yakovlev, Konstantin}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{strl, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">JCSC</abbr></div> <div id="Osipov2014b" class="col-sm-8"> <div class="title">Behavior control as a function of consciousness. I. World model and goal setting</div> <div class="author"> G. S. Osipov, A. I. Panov, and N. V. Chudova</div> <div class="periodical"> <em>Journal of Computer and Systems Sciences International</em>, 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/consc2014.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1134/S1064230714040121" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Functions that are referred in psychology as functions of consciousness are considered. These functions include reflection, consciousness of activity motivation, goal setting, synthesis of goal oriented behavior, and some others. The description is based on the concept of sign, which is widely used in psychology and, in particular, in the cultural-historical theory by Vygotsky, in which sign is interpreted informally. In this paper, we elaborate upon the concept of sign, consider mechanisms of sign formation, and some self-organization on the set of signs. Due to the work of self-organization mechanisms, a new method for the representation of the world model of an actor appears. The concept of semiotic network is introduced that is used for the examination of the actor’s world models. Models of some functions indicated above are constructed. The second part of the paper is devoted to functions of self-consciousness and to the application of the constructed models for designing plans and constructing new architectures of intelligent agents that are able, in particular, to distribute roles in coalitions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Osipov2014b</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Behavior control as a function of consciousness. I. World model and goal setting}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{53}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1064-2307}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://link.springer.com/10.1134/S1064230714040121}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1134/S1064230714040121}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{517--529}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Computer and Systems Sciences International}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Osipov, G. S. and Panov, A. I. and Chudova, N. V.}</span><span class="p">,</span>
  <span class="na">urlyear</span> <span class="p">=</span> <span class="s">{2014-09-29}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{swm, group1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Aleksandr I. Panov. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: October 26, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>